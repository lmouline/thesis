\section{Future work}

Both our contributions suffer from limitations that call for further research.
First, our work does not study all the impacts of uncertainty in software languages.
Second, our model is just one step towards (self-)explanation of \gls{adptSyst}\footnote{Explanation is a capacity of software that helps engineers to understand the system behaviour.}.
In this section, we describe two research directions left open by our work.

\subsection{Software language and uncertain data}
Software relies more and more on data to make decisions or to help decision-making processes.
Engineers should, therefore, handle the uncertainty existing in data.
In this document, we argue for managing this uncertainty at the language level.
Our contribution addresses uncertainty on values and with a limited number of probability distributions.
In our language, we focus our studies on primitive data types (numeric and boolean) and references (1:1 relation).
Moreover, we map the uncertainty propagation to operators.

However, we do not tackle the global challenge regarding the introduction of data uncertainty management at the language level.
We can formulate the challenge as follows: how to handle data uncertainty at the language level?
We can split it into different problems that call for research efforts:
\begin{itemize}
	\item What are the impacts of data uncertainty on the control flow?
	\item How to extend all data structures with uncertainty?
	\item What are the mechanisms to evaluate and reduce uncertainty and how to integrate them into the language?
	\item How to represent data uncertainty?
\end{itemize}

\paragraph{Data uncertainty and control flow}
We did not study the impact of control flow statements on the uncertainty propagation.
Introducing uncertainty as a first-class citizen will inevitably modify current behaviour of control flow statements such as \textit{IF}-conditions.
We strongly think that this new data type in the type system will lead to further research directions.
We identified two other situations that should be considered, with their challenges.
The first one is the propagation through control flow statements: how the uncertainty is propagated after an \textit{IF}-condition, a \textit{FOR}-loop and a \textit{WHILE}-loop.
The second one is the propagation from one kind of uncertainty to another one.
For example, how the uncertainty of presence should be propagated to the uncertainty of a sum, average or variance computation?

Conditional expressions, which have a boolean type, modify the control flow by forking it.
With certain boolean, the expression is evaluated at runtime, and one branch is selected according to the result.
With uncertain ones, the executor cannot decide which branch to execute.
We thus identified two possible controls flows: the classical and the uncertain execution.

For the classical one, a cast operation should be performed to get a certain one.
It can be done using at least two strategies.
First, a random selection from the probability distribution can be made.
Second, a cast can be done using the \textit{cast} or \textit{confidence} operator of our language (\cf \Cref{chapt:aintea}).
This operation gives the most confident value.
Let us take an example, an uncertain boolean that equals \false{} with a confidence of 40\%.
Following the first strategy, there is a 40\% chance of getting \false{}, and so 60\% for	 \true{}.
Using the second one, it always results in a \true{} value, as it's the most confident value.

For the uncertain execution, as the executor cannot decide which branch should be executed, it should execute all of them and propagate the uncertainty.
For example, let us imagine the following code:

\begin{lstlisting}[style=pouetpouet2, caption=Example for uncertain control flow]
uncertain_bool b = (TRUE, 0.4)
uncertain_int n;
if(uncertain_bool)
 n = (5, 0.8)
else
 n = (-5, 0.8)
\end{lstlisting}
As \textit{b} is true with a confidence of 40\%, \textit{n} should be equal to 5 with a confidence of (40\% * 80\% = 32\%) and to -5 with a confidence of (60\% * 80\% = 48\%) (considering \textit{b} and \textit{n} independent).

These two execution semantics come with several open questions.
One is related to the impact of such techniques to performances (\gls{cpu}, memory, \etc).
For the uncertain execution, additional problems persist such as: should the execution be parallel or not? How to ensure that the execution does not have a side effect(s)?
And a final one: can other semantics be defined?

\paragraph{Data structures and data uncertainty}
In a software language, it exists several data structures, from the simplest ones like arrays to complex ones like graphs or trees.
Additionally, the \gls{uml} specification contains different kinds of relations (1:1, 1:n, n:n, \etc).
While these data structure and relations are useful to build algorithms to reason over data, they come with new challenges.
First, it opens new questions concerning the meaning of an uncertain data structure: what an uncertain array? What an uncertain tree, graph?

Let us develop here the challenges brought by an uncertain array.
We think that there are three possible definitions of an uncertain array, the last one being the combination of the first two:
\begin{itemize}
	\item an uncertain array is a collection when the collection itself is uncertain,
	\item an uncertain array is a collection that contains uncertain elements,
	\item an uncertain array is a collection that contains uncertain elements and when the collection itself is uncertain.
\end{itemize}
Let us consider the following array of integers: [54, 10, 3, 24]. 
Following the first definition, the array is uncertain if this collection is not known with the most thorough confidence.
That is, the value of the array can be [6, 10, 3, 26] or [6, 10, 3, 26, 587].
As a consequence, the size of the array is also uncertain.
In the case of an ordered array, the order can also be uncertain.
Using the second definition, 54, 10, 3, and 24 are all uncertain integers.

Additionally, research efforts have to be done to specify the semantics of operators on these uncertain structures.
For example, one may focus on how the uncertainty of the array will be impacted by an \textit{add} or \textit{remove} operation.
These operations do no affect the uncertainty of uncertain arrays that respect the second definition, if we consider the operation as certain.
But it brings open questions for the two other definitions.
As they will modify the size of the collection, the size will be, in the best cases, as uncertain it was or more uncertain.

Lastly, one may investigate the impact of introducing uncertain data structures in common algorithms.
For example: how to sort an uncertain collection? How to balance an uncertain tree? How to compute the shortest path?
Let us details the sorting of an array.
If the full collection is uncertain, a common sorting algorithm can be applied without impacting the uncertainty.
In the other cases, algorithms should be redesigned.
Indeed, as uncertainty propagation is mapped to operators, and each algorithm will use the comparison operators differently, the result can differ.
Sorting the first integer array ([54, 10, 3, 24]), merge sort makes five comparisons while quick sort makes 4. 
These algorithms should consider uncertainty at a higher level than language operators.

\paragraph{Quantification and reduction of uncertainty}
In our work on uncertainty, we focus on the definition of uncertain data and the propagation of uncertainty.
However, while talking about uncertainty, there are two other key concepts: quantification and reduction.
The former is to quantify the uncertainty at runtime of a received data, \eg to find the appropriated probability distribution with its parameter.
For example, when a \gls{sg} system receives a consumption value, the quantification consists in adding the probability distribution that represents the uncertainty.
The latter is to increase the confidence of received values.
For instance, by comparing the consumption value with past ones, one may increase its confidence in the value.
The literature provides techniques to evaluate the uncertainty~\cite{wubbeler2008evaluation, metrology2008evaluation} and to reduce it~\cite{shafer1992dempster}.
Thus, we think that future work for the modelling community are open.
A direction could focus on a \gls{model} that abstracts these techniques to help engineers to manipulate and integrate them into their models.
For example, using a descriptive language that adds meta-information to uncertain values.
Below, we show a possible language for that.

\begin{lstlisting}[style=pouetPouetStyle, caption=Example of a descriptive language to define meta-information uncertainty]
uatt att1: double {
  min 0
  max 100
  past "GaussianMixtureModel"
  timeValidity 5seconds
  consistentWith att2[att1 ~ 2 * att2]
}
\end{lstlisting}

This language can define some information that can be used to quantify or reduce uncertainty.
For example, minimal and maximal values can be used to check if the received value is in this range or not.
If not, the uncertainty will increase.
The \textit{past} attribute can be used to define how it should be represented.
The model will then be used to compare the received values with past ones.
\textit{TimeValidity} is here to help the quantification of the temporal uncertainty.
More the value reaches the given validity, more it is uncertain.
Finally, \textit{consistentWith} can be used to compare the value with another one, here \textit{att2}.
Plus, the function given into square brackets can be used to formalise the relation between the two attributes.
In the listing, \textit{att1} is approximately equal to the double of \textit{att2}.
This language results from a first brainstorming, but research efforts are still required to design and validate it.

\paragraph{Data uncertainty representation}
Researchers defined different strategies, like keeping multiple possibilities, to represent several kinds of uncertainties.
As examples, we identified the uncertainty of existence and the temporal uncertainty.
The first one corresponds to the confidence that a value exists or not.
It can result from faulty data sources that send wrong data.
The second one can be used to represent the loss of confidence in value over time.

First future work would be to investigate how to introduce such techniques inside a programming language.
For example, the language should be able to store and manipulate different values for a same attribute.
Another example, the language should support a 3 dimensional representation of the value: one for the possible values, one for the confidence, and one for the time.
Then, research efforts can focus on the definition of a language that uses different strategies to handle uncertainty.
One may study the impacts on the type system, the semantics, and the syntax of the language.

Second, introducing new probability distributions lead to complex combinations of probability distributions.
In the current approach, we use an analytical approach (we compute the exact solution).
However, this cannot be performed between some probability distributions.
In such a situation, a numerical method should be applied.
This leads to challenges regarding the threshold between the performance of the language and the accuracy of the method.

\subsection{(Self-)Explanation of adaptive systems}

The complexity of adaptive system behaviour makes it hard to understand system behaviour and adaptation decisions made.
If the system enters in a suboptimal state, engineers may have difficulties to figure out the reasons.
In this thesis, we define a  temporal knowledge model to help them to perform diagnosis routines (\cf \Cref{chapt:tkm}).

However, this work is just one step towards fully explainable \glspl{adptSyst}.
To achieve this goal, research efforts should be made to answer the following challenge: how to enable autonomous explanation of system behaviour?
We identified several sub-challenges that should be addressed first:
\begin{itemize}
	\item How to accurately link decisions with their impacts?
	\item How to deal with a large amount of data required for diagnosis purpose?
	\item How to autonomously extract explanations from the data model?
\end{itemize}

\paragraph{Link effects to decisions}
When we defined our temporal knowledge model (\cf \Cref{chapt:tkm}), we assumed that designers can link \glspl{action} with their expected effects at design time with the most thorough confidence. 
However, as systems are more and more complex, we think that they do not know all the impacts in advance.
There is an unknown part.
As done by Donald Rumsfeld in a famous US Department of Defense press briefing, we can identify two levels of unknowns: unknown knowns, and unknown unknowns.
Moreover, these relations are uncertain.
All traceability links that we model in this thesis should not be considered as entirely accurate.
Lastly, decision effects will be combined with the evolution of the system context and behaviour.

Research efforts are, therefore, needed to define techniques to discover these unknown relations and to separate decisions effects from the evolution of the system.
One approach could be to use a learning algorithm to find them.
Besides, research efforts are still required to combine our two contributions and achieve our vision of an uncertain and time-aware modelling framework.

\paragraph{Large amount of data}
We are conscious that the \gls{metamodel} defined in~\Cref{chapt:tkm} remains large.
A \gls{model} that conforms this \gls{metamodel} can be challenging to be defined and manipulated manually.

Research efforts are required to define \gls{dsl} to facilitate the manipulation of the \gls{model}.
Moreover, autonomous processes can be defined to populate a \gls{model} conforms to our \gls{metamodel} automatically.
For example, one can specify a method for analysing the code or the model that describes \glspl{action} to populate the temporal knowledge with \glspl{longTermAct}.
Another process can be formalised to add \gls{model} elements related to context information, the status of action executions, \etc.

\paragraph{Automatic extraction of explanation}
In the contribution presented in~\Cref{chapt:tkm}, we defined a data model.
One can navigate in this structure to identify the causes of a suboptimal decision.
However, this task remains manual, and we strongly think that it can be long, redundant, and error-prone.
Research efforts should thus be performed to define an algorithm(s) that autonomously extracts explanations.

On a request, from a human or another system, the algorithm should collect all the information required to establish an explanation.
The algorithm should put this information in a human-readable format.
We can distinguish different kinds of information:
\begin{itemize}
	\item Information that explains why the system is defined as suboptimal. Here, the algorithm can compare the actual state  with the requirements of the systems.
	\item Information that determines if the system has ended in this state because of decisions made or because of the evolution of its context and behaviour. To achieve this, the algorithm should be able to separate decisions effects from evolution impacts. The algorithm requires thus accurate links between decisions and their effects. Moreover, it needs to know how the system evolves thanks to, for example, learning techniques or function that encodes it.
	\item Information that represents the circumstances of previous decisions. It can be collected by navigating our temporal data model.
	\item Information that details past decisions made and their execution status. If some actions have failed, data about the reasons for their failure should also be collected.
\end{itemize}

If one can achieve this research direction, we think that other research directions will be opened.
A solution could analyse the explanations to detect any sub-optimal decisions and suggest a set of correctives.
This solution would integrate learning mechanisms.





